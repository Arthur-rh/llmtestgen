from __future__ import annotations

from pathlib import Path
from typing import Iterable

from pydantic import BaseModel

from llmtestgen.services.test_generation.test_spec_generator import (
    TestCase,
    TestSpecification,
)


def _slugify(text: str, max_length: int = 60) -> str:
    """Convert a free-form description into a safe Python identifier fragment."""
    import re

    text = text.lower()
    text = re.sub(r"[^a-z0-9]+", "_", text)
    text = re.sub(r"_+", "_", text).strip("_")
    if not text:
        text = "case"
    return text[:max_length]


def render_test_case_pytest(test_case: TestCase, index: int) -> str:
    """Render a single TestCase into a pytest-style test function."""
    # Nom de fonction unique et lisible
    base_name = _slugify(test_case.id) if test_case.id else _slugify(test_case.description)
    func_name = f"test_{index:03d}_{base_name}"

    lines: list[str] = []
    lines.append(f"def {func_name}():")
    doc_parts: list[str] = []

    if test_case.requirement:
        doc_parts.append(f"Requirement: {test_case.requirement}")
    else:
        doc_parts.append(f"Description: {test_case.description}")

    # Docstring
    lines.append(f'    """')
    for part in doc_parts:
        lines.append(f"    {part}")
    lines.append(f'    """')

    # Preconditions
    if test_case.preconditions:
        lines.append("    # Preconditions")
        for pre in test_case.preconditions:
            lines.append(f"    # - {pre}")

    # Target code elements
    if test_case.target_code_elements:
        lines.append("    # Target code elements")
        for elem in test_case.target_code_elements:
            lines.append(f"    # - {elem}")

    # Steps
    if test_case.steps:
        lines.append("    # Steps")
        for i, step in enumerate(test_case.steps, start=1):
            lines.append(f"    # {i}. {step}")

    # Expected result
    if test_case.expected_result:
        lines.append("    # Expected result")
        for line in test_case.expected_result.splitlines():
            lines.append(f"    # {line}")

    # TODO / placeholder assert
    lines.append("")
    lines.append(
        '    # TODO: implement this test based on the specification above.'
    )
    lines.append(
        '    assert False, "Not implemented yet"'
    )
    lines.append("")

    return "\n".join(lines)


def render_test_spec_pytest_file(
    test_spec: TestSpecification,
    *,
    module_docstring: bool = True,
) -> str:
    """Render a whole TestSpecification into a pytest test module source code."""
    lines: list[str] = []

    if module_docstring:
        lines.append('"""')
        lines.append("Auto-generated test module from LLMTestGen.")
        lines.append(f'Source spec: {test_spec.spec_source_path}')
        if test_spec.llm_model:
            lines.append(f"Generated by model: {test_spec.llm_model}")
        lines.append('"""')
        lines.append("")

    if not test_spec.test_cases:
        lines.append("# No test cases were generated.")
        return "\n".join(lines)

    for idx, tc in enumerate(test_spec.test_cases, start=1):
        lines.append(render_test_case_pytest(tc, idx))
        lines.append("")  # blank line between tests

    return "\n".join(lines).rstrip() + "\n"


def write_test_spec_pytest_file(
    test_spec: TestSpecification,
    output_path: str | Path,
    *,
    module_docstring: bool = True,
) -> Path:
    """Render and write the pytest module to disk."""
    output_path = Path(output_path)
    output_path.parent.mkdir(parents=True, exist_ok=True)

    content = render_test_spec_pytest_file(
        test_spec,
        module_docstring=module_docstring,
    )
    output_path.write_text(content, encoding="utf-8")
    return output_path
